{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1ae7ac-24a3-4610-8bf6-801fac65f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05589be8-39f4-4de5-bc57-ef116477a15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data...\n",
      "Data extracted successfully. Rows: 199689\n",
      "Extraction time: 0.16 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract - Read the NYC Taxi CSV file\n",
    "start_time = time.time()\n",
    "print(\"Extracting data...\")\n",
    "try:\n",
    "    # Read only relevant columns to optimize memory usage\n",
    "    df = pd.read_csv('/Users/rakshithreddykondra/Desktop/2017_Yellow_Taxi_Trip_Data_20250522.csv', \n",
    "                     usecols=['tpep_pickup_datetime', 'tpep_dropoff_datetime', \n",
    "                              'trip_distance', 'fare_amount', 'PULocationID'])\n",
    "    print(f\"Data extracted successfully. Rows: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please ensure '2017_Yellow_Taxi_Trip_Data_20250522.csv' is in the directory.\")\n",
    "    exit(1)\n",
    "extract_time = time.time() - start_time\n",
    "print(f\"Extraction time: {extract_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd403b5-109c-4a8a-89fb-dc5d3b01a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/wc9gryyx2mqcrc5hm1fz0m940000gn/T/ipykernel_2588/3448972933.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'], errors='coerce')\n",
      "/var/folders/6y/wc9gryyx2mqcrc5hm1fz0m940000gn/T/ipykernel_2588/3448972933.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed successfully. Aggregated rows: 255\n",
      "Transformation time: 10.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Transform - Clean and aggregate the data\n",
    "print(\"Transforming data...\")\n",
    "# Convert datetime columns to proper format\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'], errors='coerce')\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'], errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Filter out invalid records (e.g., negative distances or fares, or unrealistic trips)\n",
    "df = df[(df['trip_distance'] > 0) & \n",
    "        (df['fare_amount'] > 0) & \n",
    "        (df['trip_distance'] < 100) & \n",
    "        (df['fare_amount'] < 500)]\n",
    "\n",
    "# Calculate trip duration in minutes\n",
    "df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "df = df[df['trip_duration'] > 0]  # Remove invalid durations\n",
    "\n",
    "# Aggregate data: Compute average trip distance and fare by pickup location\n",
    "agg_data = df.groupby('PULocationID').agg({\n",
    "    'trip_distance': 'mean',\n",
    "    'fare_amount': 'mean',\n",
    "    'PULocationID': 'count'\n",
    "}).rename(columns={'trip_distance': 'avg_trip_distance', \n",
    "                  'fare_amount': 'avg_fare_amount',\n",
    "                  'PULocationID': 'trip_count'}).reset_index()\n",
    "\n",
    "print(f\"Data transformed successfully. Aggregated rows: {len(agg_data)}\")\n",
    "transform_time = time.time() - start_time - extract_time\n",
    "print(f\"Transformation time: {transform_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98645955-c0da-482c-a8de-c4033cba8cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to PostgreSQL...\n",
      "Data loaded successfully.\n",
      "Load time: 955.89 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load - Connect to PostgreSQL and load the aggregated data\n",
    "print(\"Loading data to PostgreSQL...\")\n",
    "try:\n",
    "    # Connect to PostgreSQL \n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"taxi_data\",\n",
    "        user=\"taxi_user\",  #PostgreSQL username\n",
    "        password=\"taxidriver321\",  #PostgreSQL password\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create table for aggregated data\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS taxi_aggregates (\n",
    "            \"PULocationID\" INTEGER PRIMARY KEY,\n",
    "            \"avg_trip_distance\" FLOAT,\n",
    "            \"avg_fare_amount\" FLOAT,\n",
    "            \"trip_count\" INTEGER\n",
    "        );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "    # Use SQLAlchemy for efficient data loading\n",
    "    engine = create_engine('postgresql://taxi_user:taxidriver321@localhost:5432/taxi_data')\n",
    "    agg_data.to_sql('taxi_aggregates', engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Create an index to optimize queries\n",
    "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_pulocation ON taxi_aggregates (\"PULocationID\");')\n",
    "    conn.commit()\n",
    "    print(\"Data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data to PostgreSQL: {e}\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "load_time = time.time() - start_time - extract_time - transform_time\n",
    "print(f\"Load time: {load_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e87ca52-e303-489c-99af-ba2cbe431af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating data with sample queries...\n",
      "Top 5 pickup locations by trip count:\n",
      "(132, 29077, 31.881795233345944, 124.72203734910755)\n",
      "(138, 19499, 25.802251397507565, 114.89924765372584)\n",
      "(230, 9022, 19.877104854799377, 81.36422301041898)\n",
      "(161, 8353, 19.588861486890938, 81.76651741889141)\n",
      "(163, 7579, 20.09293706293706, 81.73039319171394)\n",
      "Query execution time: 0.00 seconds\n",
      "Total ETL pipeline execution time: 1103.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Query and Validate - Run sample queries to verify data\n",
    "print(\"Validating data with sample queries...\")\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"taxi_data\",\n",
    "        user=\"taxi_user\",\n",
    "        password=\"taxidriver321\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Query 1: Top 5 pickup locations by trip count\n",
    "    start_query_time = time.time()\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \"PULocationID\", trip_count, avg_trip_distance, avg_fare_amount\n",
    "        FROM taxi_aggregates\n",
    "        ORDER BY trip_count DESC\n",
    "        LIMIT 5;\n",
    "    \"\"\")\n",
    "    results = cursor.fetchall()\n",
    "    print(\"Top 5 pickup locations by trip count:\")\n",
    "    for row in results:\n",
    "        print(row)\n",
    "    query_time = time.time() - start_query_time\n",
    "    print(f\"Query execution time: {query_time:.2f} seconds\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error querying data: {e}\")\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "print(f\"Total ETL pipeline execution time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa42b1-5bd1-4e7c-b1f8-f9a540128275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
